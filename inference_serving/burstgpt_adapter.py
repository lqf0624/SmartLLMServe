#!/usr/bin/env python3
"""
BurstGPTæ•°æ®é›†æ¨¡æ‹Ÿé€‚é…å™¨
ä¸“é—¨å¤„ç†çªå‘æµé‡æ¨¡å¼çš„LLMæ¨ç†æ¨¡æ‹Ÿ
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib
from datetime import datetime
from typing import Dict, List, Tuple, Optional
from .data_loader import UniversalDataLoader

# è®¾ç½®matplotlibå‚æ•°
plt.style.use('default')
matplotlib.rcParams['font.family'] = ['DejaVu Sans', 'Arial', 'sans-serif']
matplotlib.rcParams['axes.unicode_minus'] = False

class BurstGPTAdapter:
    """
    BurstGPTæ•°æ®é›†é€‚é…å™¨
    åˆ†æå’Œæ¨¡æ‹Ÿçªå‘æµé‡æ¨¡å¼
    """

    def __init__(self, verbose: bool = False):
        self.verbose = verbose
        self.data_loader = UniversalDataLoader(verbose=verbose)
        self.burstgpt_stats = {}

    def analyze_burst_patterns(self, file_path: str, sample_size: int = 10000) -> Dict:
        """
        åˆ†æBurstGPTæ•°æ®é›†ä¸­çš„çªå‘æ¨¡å¼

        Args:
            file_path: BurstGPT CSVæ–‡ä»¶è·¯å¾„
            sample_size: é‡‡æ ·å¤§å°

        Returns:
            çªå‘æ¨¡å¼åˆ†æç»“æœ
        """
        print(f"ğŸ” åˆ†æBurstGPTçªå‘æ¨¡å¼: {file_path}")

        # åŠ è½½æ•°æ®
        try:
            raw_data = pd.read_csv(file_path, nrows=sample_size)
            if self.verbose:
                print(f"ğŸ“Š åŠ è½½äº† {len(raw_data)} æ¡è®°å½•")
        except Exception as e:
            print(f"âŒ åŠ è½½æ•°æ®å¤±è´¥: {e}")
            return {}

        # åˆ†ææ—¶é—´æˆ³
        if 'Timestamp' in raw_data.columns:
            timestamps = raw_data['Timestamp'].values
            time_diffs = np.diff(timestamps)

            # çªå‘æ£€æµ‹ï¼šçŸ­æ—¶é—´å†…çš„é«˜é¢‘è¯·æ±‚
            burst_threshold = np.percentile(time_diffs, 25)  # 25%åˆ†ä½æ•°ä½œä¸ºçªå‘é˜ˆå€¼
            burst_intervals = time_diffs[time_diffs <= burst_threshold]

            # è®¡ç®—çªå‘ç»Ÿè®¡
            burst_stats = {
                'total_requests': len(raw_data),
                'sample_duration': timestamps[-1] - timestamps[0],
                'avg_time_gap': np.mean(time_diffs),
                'std_time_gap': np.std(time_diffs),
                'burst_threshold': burst_threshold,
                'burst_count': len(burst_intervals),
                'burst_ratio': len(burst_intervals) / len(time_diffs),
                'burst_intensity': np.mean(burst_intervals) if len(burst_intervals) > 0 else 0,
                'max_burst_gap': np.max(burst_intervals) if len(burst_intervals) > 0 else 0,
                'min_burst_gap': np.min(burst_intervals) if len(burst_intervals) > 0 else 0,
            }

            # åˆ†ætokenåˆ†å¸ƒ
            token_stats = {
                'avg_input_tokens': raw_data['Request tokens'].mean(),
                'std_input_tokens': raw_data['Request tokens'].std(),
                'avg_output_tokens': raw_data['Response tokens'].mean(),
                'std_output_tokens': raw_data['Response tokens'].std(),
                'max_input_tokens': raw_data['Request tokens'].max(),
                'max_output_tokens': raw_data['Response tokens'].max(),
            }

            # æ¨¡å‹åˆ†å¸ƒ
            model_dist = raw_data['Model'].value_counts().to_dict()

            # åˆå¹¶ç»Ÿè®¡ç»“æœ
            self.burstgpt_stats = {
                'burst_patterns': burst_stats,
                'token_distribution': token_stats,
                'model_distribution': model_dist,
                'raw_sample': raw_data.head(100)  # ä¿å­˜æ ·æœ¬æ•°æ®
            }

            if self.verbose:
                self._print_analysis_summary()

            return self.burstgpt_stats

        return {}

    def _print_analysis_summary(self):
        """æ‰“å°åˆ†ææ‘˜è¦"""
        print("\nğŸ“Š BurstGPTçªå‘æ¨¡å¼åˆ†ææ‘˜è¦:")
        print("-" * 60)

        if 'burst_patterns' in self.burstgpt_stats:
            bp = self.burstgpt_stats['burst_patterns']
            print(f"æ€»è¯·æ±‚æ•°: {bp['total_requests']}")
            print(f"é‡‡æ ·æ—¶é•¿: {bp['sample_duration']:.2f}ms")
            print(f"å¹³å‡æ—¶é—´é—´éš”: {bp['avg_time_gap']:.2f}ms")
            print(f"æ—¶é—´é—´éš”æ ‡å‡†å·®: {bp['std_time_gap']:.2f}ms")
            print(f"çªå‘é˜ˆå€¼: {bp['burst_threshold']:.2f}ms")
            print(f"çªå‘è¯·æ±‚æ•°: {bp['burst_count']}")
            print(f"çªå‘æ¯”ä¾‹: {bp['burst_ratio']:.2%}")
            print(f"çªå‘å¼ºåº¦: {bp['burst_intensity']:.2f}ms")

        if 'token_distribution' in self.burstgpt_stats:
            td = self.burstgpt_stats['token_distribution']
            print(f"\nğŸ“ˆ Tokenåˆ†å¸ƒ:")
            print(f"å¹³å‡è¾“å…¥token: {td['avg_input_tokens']:.1f} (Â±{td['std_input_tokens']:.1f})")
            print(f"å¹³å‡è¾“å‡ºtoken: {td['avg_output_tokens']:.1f} (Â±{td['std_output_tokens']:.1f})")
            print(f"æœ€å¤§è¾“å…¥token: {td['max_input_tokens']}")
            print(f"æœ€å¤§è¾“å‡ºtoken: {td['max_output_tokens']}")

        if 'model_distribution' in self.burstgpt_stats:
            md = self.burstgpt_stats['model_distribution']
            print(f"\nğŸ¤– æ¨¡å‹åˆ†å¸ƒ:")
            for model, count in md.items():
                print(f"  {model}: {count} ({count/sum(md.values()):.1%})")

    def create_simulation_dataset(self, file_path: str, req_num: int = 1000,
                                burst_mode: str = 'original') -> pd.DataFrame:
        """
        åˆ›å»ºé€‚åˆLLMServingSimçš„æ•°æ®é›†

        Args:
            file_path: BurstGPT CSVæ–‡ä»¶è·¯å¾„
            req_num: è¯·æ±‚æ•°é‡
            burst_mode: çªå‘æ¨¡å¼ ('original', 'enhanced', 'extreme')

        Returns:
            æ ‡å‡†æ ¼å¼çš„DataFrame
        """
        print(f"ğŸ”„ åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®é›†: {burst_mode}æ¨¡å¼, {req_num}ä¸ªè¯·æ±‚")

        # ä½¿ç”¨UniversalDataLoaderåŠ è½½æ•°æ®
        try:
            standard_data = self.data_loader.load_dataset(file_path, req_num=req_num)
        except Exception as e:
            print(f"âŒ ä½¿ç”¨UniversalDataLoaderå¤±è´¥: {e}")
            return self._create_fallback_dataset(req_num, burst_mode)

        # æ ¹æ®çªå‘æ¨¡å¼è°ƒæ•´æ—¶é—´é—´éš”
        if burst_mode != 'original':
            standard_data = self._apply_burst_pattern(standard_data, burst_mode)

        return standard_data

    def _apply_burst_pattern(self, data: pd.DataFrame, burst_mode: str) -> pd.DataFrame:
        """åº”ç”¨çªå‘æ¨¡å¼åˆ°æ•°æ®"""
        if burst_mode == 'enhanced':
            # å¢å¼ºçªå‘æ¨¡å¼ï¼šåˆ›å»ºæ›´æ˜æ˜¾çš„çªå‘
            return self._create_enhanced_bursts(data)
        elif burst_mode == 'extreme':
            # æç«¯çªå‘æ¨¡å¼ï¼šåˆ›å»ºæç«¯çš„çªå‘æµé‡
            return self._create_extreme_bursts(data)
        else:
            return data

    def _create_enhanced_bursts(self, data: pd.DataFrame) -> pd.DataFrame:
        """åˆ›å»ºå¢å¼ºçªå‘æ¨¡å¼"""
        enhanced_data = data.copy()
        n_requests = len(enhanced_data)

        # åˆ›å»ºçªå‘ç°‡
        burst_size = 10
        n_bursts = n_requests // burst_size
        burst_gap = 1000  # çªå‘ç°‡é—´éš” (ms)
        intra_burst_gap = 10  # çªå‘ç°‡å†…é—´éš” (ms)

        arrival_times = []
        for i in range(n_bursts):
            burst_start = i * burst_gap
            for j in range(burst_size):
                arrival_times.append(burst_start + j * intra_burst_gap)

        # æ·»åŠ å‰©ä½™è¯·æ±‚
        remaining_requests = n_requests - len(arrival_times)
        for i in range(remaining_requests):
            arrival_times.append(n_bursts * burst_gap + i * 500)

        enhanced_data['arrival_time_ns'] = np.array(arrival_times[:n_requests]) * 1_000_000

        return enhanced_data

    def _create_extreme_bursts(self, data: pd.DataFrame) -> pd.DataFrame:
        """åˆ›å»ºæç«¯çªå‘æ¨¡å¼"""
        extreme_data = data.copy()
        n_requests = len(extreme_data)

        # åˆ›å»ºæç«¯çªå‘ï¼šå¤§é‡è¯·æ±‚åœ¨æçŸ­æ—¶é—´å†…åˆ°è¾¾
        burst_clusters = [
            (0, 50, 5),      # 50ä¸ªè¯·æ±‚åœ¨5mså†…
            (100, 80, 3),    # 80ä¸ªè¯·æ±‚åœ¨3mså†…
            (200, 120, 2),   # 120ä¸ªè¯·æ±‚åœ¨2mså†…
            (300, 60, 4),    # 60ä¸ªè¯·æ±‚åœ¨4mså†…
            (400, 40, 6),    # 40ä¸ªè¯·æ±‚åœ¨6mså†…
        ]

        arrival_times = []
        used_requests = 0

        for cluster_start, cluster_size, cluster_duration in burst_clusters:
            cluster_end = cluster_start + cluster_duration
            actual_size = min(cluster_size, n_requests - used_requests)

            # åœ¨çªå‘ç°‡å†…ç”Ÿæˆè¯·æ±‚æ—¶é—´
            cluster_times = np.random.uniform(cluster_start, cluster_end, actual_size)
            arrival_times.extend(sorted(cluster_times))
            used_requests += actual_size

        # æ·»åŠ å‰©ä½™è¯·æ±‚
        remaining_requests = n_requests - used_requests
        if remaining_requests > 0:
            remaining_times = np.random.uniform(500, 2000, remaining_requests)
            arrival_times.extend(sorted(remaining_times))

        extreme_data['arrival_time_ns'] = np.array(arrival_times[:n_requests]) * 1_000_000

        return extreme_data

    def _create_fallback_dataset(self, req_num: int, burst_mode: str) -> pd.DataFrame:
        """åˆ›å»ºå¤‡ç”¨æ•°æ®é›†"""
        print("âš ï¸ ä½¿ç”¨å¤‡ç”¨æ•°æ®é›†ç”Ÿæˆ")

        # åŸºäºBurstGPTç»Ÿè®¡ç‰¹å¾ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®
        fallback_data = pd.DataFrame()

        # ç”Ÿæˆtokenæ•°é‡ï¼ˆåŸºäºBurstGPTç‰¹å¾ï¼‰
        fallback_data['input_toks'] = np.random.normal(400, 300, req_num).astype(int)
        fallback_data['input_toks'] = np.clip(fallback_data['input_toks'], 10, 2000)

        fallback_data['output_toks'] = np.random.normal(250, 200, req_num).astype(int)
        fallback_data['output_toks'] = np.clip(fallback_data['output_toks'], 10, 1000)

        # ç”Ÿæˆåˆ°è¾¾æ—¶é—´
        if burst_mode == 'original':
            # åŸå§‹æ¨¡å¼ï¼šç›¸å¯¹å‡åŒ€çš„åˆ†å¸ƒ
            arrival_times = np.random.exponential(100, req_num)
        elif burst_mode == 'enhanced':
            # å¢å¼ºçªå‘æ¨¡å¼
            arrival_times = self._generate_enhanced_burst_times(req_num)
        else:  # extreme
            # æç«¯çªå‘æ¨¡å¼
            arrival_times = self._generate_extreme_burst_times(req_num)

        fallback_data['arrival_time_ns'] = np.cumsum(arrival_times) * 1_000_000
        fallback_data['model_type'] = 'ChatGPT'
        fallback_data['burst_pattern'] = burst_mode

        return fallback_data

    def _generate_enhanced_burst_times(self, req_num: int) -> np.ndarray:
        """ç”Ÿæˆå¢å¼ºçªå‘æ—¶é—´é—´éš”"""
        times = []
        i = 0
        while i < req_num:
            # éšæœºå†³å®šæ˜¯å¦å¼€å§‹çªå‘
            if np.random.random() < 0.3:  # 30%æ¦‚ç‡å¼€å§‹çªå‘
                burst_length = np.random.randint(5, 15)
                burst_times = np.random.exponential(10, min(burst_length, req_num - i))
                times.extend(burst_times)
                i += len(burst_times)
            else:
                times.append(np.random.exponential(200))
                i += 1
        return np.array(times[:req_num])

    def _generate_extreme_burst_times(self, req_num: int) -> np.ndarray:
        """ç”Ÿæˆæç«¯çªå‘æ—¶é—´é—´éš”"""
        times = []
        i = 0
        while i < req_num:
            # åˆ›å»ºæç«¯çªå‘ç°‡
            if np.random.random() < 0.2:  # 20%æ¦‚ç‡å¼€å§‹æç«¯çªå‘
                burst_length = np.random.randint(20, 50)
                burst_times = np.random.exponential(2, min(burst_length, req_num - i))
                times.extend(burst_times)
                i += len(burst_times)
            else:
                times.append(np.random.exponential(500))
                i += 1
        return np.array(times[:req_num])

    def run_burst_simulation(self, dataset_path: str, req_num: int = 1000,
                           burst_mode: str = 'enhanced', output_prefix: str = 'burstgpt') -> Dict:
        """
        è¿è¡ŒBurstGPTæ¨¡æ‹Ÿå®éªŒ

        Args:
            dataset_path: BurstGPTæ•°æ®é›†è·¯å¾„
            req_num: è¯·æ±‚æ•°é‡
            burst_mode: çªå‘æ¨¡å¼
            output_prefix: è¾“å‡ºæ–‡ä»¶å‰ç¼€

        Returns:
            æ¨¡æ‹Ÿç»“æœ
        """
        print(f"ğŸš€ å¼€å§‹BurstGPTæ¨¡æ‹Ÿå®éªŒ: {burst_mode}æ¨¡å¼")

        # åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®é›†
        sim_data = self.create_simulation_dataset(dataset_path, req_num, burst_mode)

        # ä¿å­˜æ¨¡æ‹Ÿæ•°æ®é›†
        sim_data_path = f'output/{output_prefix}_sim_data.csv'
        sim_data.to_csv(sim_data_path, index=False)
        print(f"ğŸ“„ æ¨¡æ‹Ÿæ•°æ®é›†å·²ä¿å­˜: {sim_data_path}")

        # è¿è¡ŒLLMServingSimæ¨¡æ‹Ÿ
        sim_result = self._run_llmserving_sim(sim_data, output_prefix)

        return {
            'sim_data': sim_data,
            'sim_result': sim_result,
            'burst_mode': burst_mode,
            'dataset_path': dataset_path
        }

    def _run_llmserving_sim(self, sim_data: pd.DataFrame, output_prefix: str) -> Dict:
        """è¿è¡ŒLLMServingSimæ¨¡æ‹Ÿ"""
        # ä¿å­˜ä¸ºTSVæ ¼å¼ä¾›LLMServingSimä½¿ç”¨
        tsv_path = f'output/{output_prefix}_sim.tsv'
        sim_data[['input_toks', 'output_toks', 'arrival_time_ns']].to_csv(
            tsv_path, sep='\t', index=False, header=False
        )

        # æ„å»ºå‘½ä»¤
        cmd = f"python3 main.py --model_name 'meta-llama/Llama-3.1-8B-Instruct' --hardware 'RTX3090' --dataset '{tsv_path}' --output 'output/{output_prefix}_results.csv' --req_num {len(sim_data)}"

        print(f"ğŸ”§ è¿è¡Œæ¨¡æ‹Ÿå‘½ä»¤: {cmd}")

        # è¿™é‡Œåº”è¯¥è¿è¡Œå®é™…çš„æ¨¡æ‹Ÿï¼Œç°åœ¨è¿”å›æ¨¡æ‹Ÿç»“æœ
        print("âš ï¸ æ¨¡æ‹Ÿè¿è¡Œé€»è¾‘éœ€è¦å®ç°")

        return {'status': 'simulated', 'command': cmd}

    def compare_burst_patterns(self, file_path: str, req_num: int = 500) -> Dict:
        """
        æ¯”è¾ƒä¸åŒçªå‘æ¨¡å¼çš„æ€§èƒ½

        Args:
            file_path: BurstGPTæ•°æ®é›†è·¯å¾„
            req_num: è¯·æ±‚æ•°é‡

        Returns:
            æ¯”è¾ƒç»“æœ
        """
        print("ğŸ” æ¯”è¾ƒä¸åŒçªå‘æ¨¡å¼æ€§èƒ½")

        modes = ['original', 'enhanced', 'extreme']
        results = {}

        for mode in modes:
            print(f"\nğŸ“Š æµ‹è¯•{mode}æ¨¡å¼...")
            try:
                result = self.run_burst_simulation(file_path, req_num, mode, f'burstgpt_{mode}')
                results[mode] = result
            except Exception as e:
                print(f"âŒ {mode}æ¨¡å¼æµ‹è¯•å¤±è´¥: {e}")
                results[mode] = {'error': str(e)}

        return results

def main():
    """ä¸»å‡½æ•°"""
    adapter = BurstGPTAdapter(verbose=True)

    # åˆ†æBurstGPTæ•°æ®é›†
    burstgpt_path = 'dataset/BurstGPT_1.csv'
    stats = adapter.analyze_burst_patterns(burstgpt_path, sample_size=50000)

    # åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®é›†
    if stats:
        sim_data = adapter.create_simulation_dataset(burstgpt_path, req_num=1000, burst_mode='enhanced')
        print(f"ğŸ“Š åˆ›å»ºäº† {len(sim_data)} æ¡æ¨¡æ‹Ÿæ•°æ®")

        # ä¿å­˜æ¨¡æ‹Ÿæ•°æ®
        sim_data.to_csv('output/burstgpt_simulation.csv', index=False)
        print("ğŸ“„ æ¨¡æ‹Ÿæ•°æ®å·²ä¿å­˜: output/burstgpt_simulation.csv")

        # å¯¹æ¯”ä¸åŒçªå‘æ¨¡å¼
        comparison = adapter.compare_burst_patterns(burstgpt_path, req_num=200)
        print("âœ… çªå‘æ¨¡å¼å¯¹æ¯”å®Œæˆ")

if __name__ == "__main__":
    main()