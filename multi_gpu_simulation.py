#!/usr/bin/env python3
"""
å¤šå¡ç¯å¢ƒLLMæ¨ç†æ¨¡æ‹Ÿè„šæœ¬

æ”¯æŒå¤šç§GPUé…ç½®å’Œæ•°æ®é›†çš„å¹¶è¡Œæ¨¡æ‹Ÿå®éªŒ
é€‚ç”¨äºå¤§è§„æ¨¡æ¨ç†ç¯å¢ƒæ€§èƒ½æµ‹è¯•å’Œä¼˜åŒ–åˆ†æ

ä½œè€…: SmartLLMServe Team
æ—¥æœŸ: 2025-09-28
"""

import subprocess
import os
import json
import time
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Optional
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np

class MultiGPUSimulator:
    """å¤šå¡æ¨¡æ‹Ÿå™¨ç±»"""

    def __init__(self, base_config: Dict = None):
        self.base_config = base_config or {
            "base_hardware": "RTX3090",
            "base_dataset": "dataset/BurstGPT_1.csv",
            "output_dir": "output/multi_gpu_results",
            "timeout": 600,  # 10åˆ†é’Ÿè¶…æ—¶
            "verbose": True
        }
        self.results = {}
        self.ensure_output_dir()

    def ensure_output_dir(self):
        """ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨"""
        os.makedirs(self.base_config["output_dir"], exist_ok=True)

    def get_gpu_configs(self) -> List[Dict]:
        """è·å–GPUé…ç½®åˆ—è¡¨"""
        return [
            {
                "npu_num": 1,
                "npu_group": 1,
                "name": "single_gpu",
                "description": "å•GPUåŸºå‡†æµ‹è¯•"
            },
            {
                "npu_num": 2,
                "npu_group": 1,
                "name": "dual_gpu",
                "description": "åŒGPUå¹¶è¡Œ"
            },
            {
                "npu_num": 4,
                "npu_group": 1,
                "name": "quad_gpu",
                "description": "å››GPUå¹¶è¡Œ"
            },
            {
                "npu_num": 8,
                "npu_group": 1,
                "name": "octa_gpu",
                "description": "å…«GPUå¹¶è¡Œ"
            },
            {
                "npu_num": 16,
                "npu_group": 1,
                "name": "hexadeca_gpu",
                "description": "åå…­GPUå¹¶è¡Œ"
            }
        ]

    def get_dataset_configs(self) -> List[Dict]:
        """è·å–æ•°æ®é›†é…ç½®åˆ—è¡¨"""
        return [
            {
                "path": "dataset/BurstGPT_1_cleaned.csv",
                "name": "burstgpt_full",
                "description": "å®Œæ•´BurstGPTæ•°æ®é›†",
                "sample_size": None
            },
            {
                "path": "dataset/BurstGPT_1_cleaned.csv",
                "name": "burstgpt_sample",
                "description": "BurstGPTé‡‡æ ·æ•°æ®é›†",
                "sample_size": 10000
            },
            {
                "path": "dataset/BurstGPT_1.csv",
                "name": "burstgpt_full",
                "description": "BurstGPTå®Œæ•´æ•°æ®é›†ï¼ˆçœŸå®ç”Ÿäº§ç¯å¢ƒï¼‰",
                "sample_size": None
            }
        ]

    def create_sample_dataset(self, original_path: str, sample_size: int, output_path: str) -> bool:
        """åˆ›å»ºé‡‡æ ·æ•°æ®é›†"""
        try:
            df = pd.read_csv(original_path)
            if len(df) > sample_size:
                sampled_df = df.sample(n=sample_size, random_state=42)
                sampled_df.to_csv(output_path, index=False)
                print(f"âœ… åˆ›å»ºé‡‡æ ·æ•°æ®é›†: {output_path} ({sample_size} ä¸ªè¯·æ±‚)")
                return True
            else:
                print(f"â„¹ï¸ æ•°æ®é›†å·²å°äºé‡‡æ ·å¤§å°ï¼Œç›´æ¥ä½¿ç”¨åŸæ–‡ä»¶")
                return False
        except Exception as e:
            print(f"âŒ åˆ›å»ºé‡‡æ ·æ•°æ®é›†å¤±è´¥: {e}")
            return False

    def run_single_simulation(self, config: Dict) -> Dict:
        """è¿è¡Œå•ä¸ªæ¨¡æ‹Ÿå®éªŒ"""
        experiment_name = f"{config['dataset_name']}_{config['gpu_name']}"
        output_file = f"{self.base_config['output_dir']}/{experiment_name}.csv"

        print(f"\nğŸš€ å¼€å§‹å®éªŒ: {experiment_name}")
        print(f"   GPUé…ç½®: {config['gpu_num']}å¡ ({config['gpu_description']})")
        print(f"   æ•°æ®é›†: {config['dataset_description']}")

        # å‡†å¤‡æ•°æ®é›†è·¯å¾„
        dataset_path = config["dataset_path"]
        if config["sample_size"] and config["sample_size"] > 0:
            sample_path = f"temp_sample_{config['dataset_name']}.csv"
            if self.create_sample_dataset(dataset_path, config["sample_size"], sample_path):
                dataset_path = sample_path

        # æ„å»ºå‘½ä»¤
        cmd = [
            "python", "main.py",
            "--hardware", self.base_config["base_hardware"],
            "--npu_num", str(config["gpu_num"]),
            "--npu_group", str(config["gpu_group"]),
            "--dataset", dataset_path,
            "--output", output_file
        ]

        # æ·»åŠ è°ƒåº¦å™¨å‚æ•°
        if config.get("scheduler"):
            cmd.extend(["--scheduler", config["scheduler"]])

        print(f"   å‘½ä»¤: {' '.join(cmd)}")

        # è®°å½•å¼€å§‹æ—¶é—´
        start_time = time.time()

        try:
            # è¿è¡Œæ¨¡æ‹Ÿ
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=self.base_config["timeout"],
                cwd="/mnt/f/LLMServingSim"
            )

            # è®°å½•ç»“æŸæ—¶é—´
            end_time = time.time()
            execution_time = end_time - start_time

            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if config["sample_size"] and config["sample_size"] > 0 and os.path.exists(sample_path):
                os.remove(sample_path)

            # å¤„ç†ç»“æœ
            if result.returncode == 0:
                print(f"âœ… å®éªŒå®Œæˆ: {execution_time:.2f}ç§’")

                # è§£æè¾“å‡ºæ–‡ä»¶
                if os.path.exists(output_file):
                    stats = self.analyze_results(output_file)
                    return {
                        "status": "success",
                        "execution_time": execution_time,
                        "stats": stats,
                        "config": config,
                        "output_file": output_file
                    }
                else:
                    print(f"âš ï¸ è¾“å‡ºæ–‡ä»¶ä¸å­˜åœ¨: {output_file}")
                    return {
                        "status": "warning",
                        "execution_time": execution_time,
                        "error": "è¾“å‡ºæ–‡ä»¶ä¸å­˜åœ¨",
                        "config": config
                    }
            else:
                print(f"âŒ å®éªŒå¤±è´¥: {result.stderr}")
                return {
                    "status": "failed",
                    "execution_time": execution_time,
                    "error": result.stderr,
                    "config": config
                }

        except subprocess.TimeoutExpired:
            print(f"â° å®éªŒè¶…æ—¶: {self.base_config['timeout']}ç§’")
            return {
                "status": "timeout",
                "execution_time": self.base_config["timeout"],
                "error": "å®éªŒè¶…æ—¶",
                "config": config
            }
        except Exception as e:
            print(f"âŒ å®éªŒå¼‚å¸¸: {e}")
            return {
                "status": "error",
                "execution_time": time.time() - start_time,
                "error": str(e),
                "config": config
            }

    def analyze_results(self, result_file: str) -> Dict:
        """åˆ†ææ¨¡æ‹Ÿç»“æœ"""
        try:
            df = pd.read_csv(result_file)

            # åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯
            stats = {
                "total_requests": len(df),
                "avg_latency_ms": df["latency"].mean() / 1e6,
                "avg_ttft_ms": df["TTFT"].mean() / 1e6,
                "avg_tpot_ms": df["TPOT"].mean() / 1e6,
                "avg_queue_delay_ms": df["queuing_delay"].mean() / 1e6,
                "throughput_tokens_per_sec": df["output"].sum() / (df["end_time"].max() - df["arrival"].min()) * 1e9,
                "total_execution_time_sec": (df["end_time"].max() - df["arrival"].min()) / 1e9,
                "latency_std_ms": df["latency"].std() / 1e6,
                "total_output_tokens": df["output"].sum()
            }

            return stats

        except Exception as e:
            print(f"âŒ åˆ†æç»“æœå¤±è´¥: {e}")
            return {"error": str(e)}

    def run_comprehensive_experiment(self, datasets: List[str] = None, gpus: List[str] = None) -> Dict:
        """è¿è¡Œç»¼åˆå®éªŒ"""
        print("ğŸ¯ å¼€å§‹å¤šå¡ç¯å¢ƒç»¼åˆæ¨¡æ‹Ÿå®éªŒ")
        print("=" * 60)

        # è·å–é…ç½®
        gpu_configs = self.get_gpu_configs()
        dataset_configs = self.get_dataset_configs()

        # è¿‡æ»¤é…ç½®
        if datasets:
            dataset_configs = [d for d in dataset_configs if d["name"] in datasets]
        if gpus:
            gpu_configs = [g for g in gpu_configs if g["name"] in gpus]

        all_results = {}

        for dataset_config in dataset_configs:
            dataset_results = {}
            print(f"\nğŸ“Š æ•°æ®é›†: {dataset_config['description']}")

            for gpu_config in gpu_configs:
                # æ„å»ºå®éªŒé…ç½®
                experiment_config = {
                    "dataset_name": dataset_config["name"],
                    "dataset_description": dataset_config["description"],
                    "dataset_path": dataset_config["path"],
                    "sample_size": dataset_config["sample_size"],
                    "gpu_name": gpu_config["name"],
                    "gpu_description": gpu_config["description"],
                    "gpu_num": gpu_config["npu_num"],
                    "gpu_group": gpu_config["npu_group"]
                }

                # è¿è¡Œå®éªŒ
                result = self.run_single_simulation(experiment_config)
                dataset_results[gpu_config["name"]] = result

            all_results[dataset_config["name"]] = dataset_results

        self.results = all_results
        return all_results

    def generate_summary_report(self) -> str:
        """ç”Ÿæˆå®éªŒæ€»ç»“æŠ¥å‘Š"""
        if not self.results:
            return "æ²¡æœ‰å¯ç”¨çš„å®éªŒç»“æœ"

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_path = f"{self.base_config['output_dir']}/experiment_report_{timestamp}.md"

        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("# å¤šå¡ç¯å¢ƒæ¨¡æ‹Ÿå®éªŒæŠ¥å‘Š\n\n")
            f.write(f"**å®éªŒæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")

            for dataset_name, dataset_results in self.results.items():
                f.write(f"## {dataset_name} æ•°æ®é›†\n\n")

                # åˆ›å»ºæ€§èƒ½å¯¹æ¯”è¡¨æ ¼
                f.write("| GPUé…ç½® | çŠ¶æ€ | æ‰§è¡Œæ—¶é—´(ç§’) | å¹³å‡å»¶è¿Ÿ(ms) | ååé‡(tokens/s) | è¯·æ±‚æ•° |\n")
                f.write("|---------|------|-------------|-------------|------------------|--------|\n")

                for gpu_name, result in dataset_results.items():
                    status = "âœ… æˆåŠŸ" if result["status"] == "success" else f"âŒ {result['status']}"
                    exec_time = f"{result['execution_time']:.2f}"

                    if result["status"] == "success" and "stats" in result:
                        avg_latency = f"{result['stats']['avg_latency_ms']:.2f}"
                        throughput = f"{result['stats']['throughput_tokens_per_sec']:.2f}"
                        requests = str(result['stats']['total_requests'])
                    else:
                        avg_latency = "N/A"
                        throughput = "N/A"
                        requests = "N/A"

                    f.write(f"| {gpu_name} | {status} | {exec_time} | {avg_latency} | {throughput} | {requests} |\n")

                f.write("\n")

            # æ€»ç»“å’Œå»ºè®®
            f.write("## å®éªŒæ€»ç»“\n\n")
            successful_experiments = sum(1 for d in self.results.values() for r in d.values() if r["status"] == "success")
            total_experiments = sum(len(d) for d in self.results.values())
            f.write(f"- **å®éªŒå®Œæˆç‡**: {successful_experiments}/{total_experiments} ({successful_experiments/total_experiments*100:.1f}%)\n")

            if successful_experiments > 0:
                f.write("- **æˆåŠŸçš„å®éªŒé…ç½®**: \n")
                for dataset_name, dataset_results in self.results.items():
                    for gpu_name, result in dataset_results.items():
                        if result["status"] == "success":
                            f.write(f"  - {dataset_name} + {gpu_name}\n")

            f.write("\n## å»ºè®®çš„åç»­å®éªŒ\n")
            f.write("1. **æ‰©å±•GPUé…ç½®**: æµ‹è¯•æ›´å¤šçš„GPUå¹¶è¡Œæ¨¡å¼\n")
            f.write("2. **è°ƒåº¦å™¨ä¼˜åŒ–**: å¯¹æ¯”ä¸åŒè°ƒåº¦ç­–ç•¥çš„æ€§èƒ½\n")
            f.write("3. **å†…å­˜ç®¡ç†**: åˆ†æä¸åŒGPUé…ç½®ä¸‹çš„å†…å­˜ä½¿ç”¨æƒ…å†µ\n")
            f.write("4. **çœŸå®æ•°æ®**: ä½¿ç”¨æ›´çœŸå®çš„å¤§è§„æ¨¡æ•°æ®é›†è¿›è¡ŒéªŒè¯\n")

        print(f"ğŸ“„ å®éªŒæŠ¥å‘Šå·²ä¿å­˜: {report_path}")
        return report_path

    def create_performance_charts(self):
        """åˆ›å»ºæ€§èƒ½å¯¹æ¯”å›¾è¡¨"""
        if not self.results:
            print("âŒ æ²¡æœ‰å¯ç”¨çš„å®éªŒç»“æœ")
            return

        # å‡†å¤‡æ•°æ®
        data = []
        for dataset_name, dataset_results in self.results.items():
            for gpu_name, result in dataset_results.items():
                if result["status"] == "success" and "stats" in result:
                    data.append({
                        "dataset": dataset_name,
                        "gpu_config": gpu_name,
                        "gpu_num": int(gpu_name.split('_')[0]) if '_' in gpu_name else 1,
                        "avg_latency_ms": result["stats"]["avg_latency_ms"],
                        "throughput": result["stats"]["throughput_tokens_per_sec"],
                        "execution_time": result["execution_time"]
                    })

        if not data:
            print("âŒ æ²¡æœ‰æˆåŠŸçš„å®éªŒæ•°æ®")
            return

        df = pd.DataFrame(data)

        # åˆ›å»ºå›¾è¡¨
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        fig.suptitle('å¤šå¡ç¯å¢ƒæ€§èƒ½å¯¹æ¯”åˆ†æ', fontsize=16, fontweight='bold')

        # 1. å»¶è¿Ÿ vs GPUæ•°é‡
        ax1 = axes[0, 0]
        for dataset in df['dataset'].unique():
            dataset_df = df[df['dataset'] == dataset]
            ax1.plot(dataset_df['gpu_num'], dataset_df['avg_latency_ms'],
                    marker='o', label=dataset, linewidth=2)
        ax1.set_xlabel('GPUæ•°é‡')
        ax1.set_ylabel('å¹³å‡å»¶è¿Ÿ (ms)')
        ax1.set_title('å»¶è¿ŸéšGPUæ•°é‡å˜åŒ–')
        ax1.legend()
        ax1.grid(True, alpha=0.3)

        # 2. ååé‡ vs GPUæ•°é‡
        ax2 = axes[0, 1]
        for dataset in df['dataset'].unique():
            dataset_df = df[df['dataset'] == dataset]
            ax2.plot(dataset_df['gpu_num'], dataset_df['throughput'],
                    marker='s', label=dataset, linewidth=2)
        ax2.set_xlabel('GPUæ•°é‡')
        ax2.set_ylabel('ååé‡ (tokens/s)')
        ax2.set_title('ååé‡éšGPUæ•°é‡å˜åŒ–')
        ax2.legend()
        ax2.grid(True, alpha=0.3)

        # 3. æ‰§è¡Œæ—¶é—´ vs GPUæ•°é‡
        ax3 = axes[1, 0]
        for dataset in df['dataset'].unique():
            dataset_df = df[df['dataset'] == dataset]
            ax3.plot(dataset_df['gpu_num'], dataset_df['execution_time'],
                    marker='^', label=dataset, linewidth=2)
        ax3.set_xlabel('GPUæ•°é‡')
        ax3.set_ylabel('æ‰§è¡Œæ—¶é—´ (ç§’)')
        ax3.set_title('æ‰§è¡Œæ—¶é—´éšGPUæ•°é‡å˜åŒ–')
        ax3.legend()
        ax3.grid(True, alpha=0.3)

        # 4. æ€§èƒ½æ•ˆç‡åˆ†æ
        ax4 = axes[1, 1]
        for dataset in df['dataset'].unique():
            dataset_df = df[df['dataset'] == dataset]
            # è®¡ç®—æ•ˆç‡æŒ‡æ ‡ (ååé‡/GPUæ•°é‡)
            efficiency = dataset_df['throughput'] / dataset_df['gpu_num']
            ax4.plot(dataset_df['gpu_num'], efficiency,
                    marker='d', label=dataset, linewidth=2)
        ax4.set_xlabel('GPUæ•°é‡')
        ax4.set_ylabel('æ¯GPUååé‡ (tokens/s)')
        ax4.set_title('GPUåˆ©ç”¨æ•ˆç‡')
        ax4.legend()
        ax4.grid(True, alpha=0.3)

        plt.tight_layout()

        # ä¿å­˜å›¾è¡¨
        chart_path = f"{self.base_config['output_dir']}/performance_comparison.png"
        plt.savefig(chart_path, dpi=300, bbox_inches='tight')
        print(f"ğŸ“Š æ€§èƒ½å¯¹æ¯”å›¾è¡¨å·²ä¿å­˜: {chart_path}")
        plt.close()

        return chart_path

    def save_results_json(self):
        """ä¿å­˜ç»“æœä¸ºJSONæ ¼å¼"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        json_path = f"{self.base_config['output_dir']}/experiment_results_{timestamp}.json"

        # å‡†å¤‡JSONæ•°æ®
        json_data = {
            "experiment_time": datetime.now().isoformat(),
            "base_config": self.base_config,
            "results": self.results
        }

        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(json_data, f, indent=2, ensure_ascii=False, default=str)

        print(f"ğŸ’¾ å®éªŒç»“æœå·²ä¿å­˜: {json_path}")
        return json_path

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ å¤šå¡ç¯å¢ƒLLMæ¨ç†æ¨¡æ‹Ÿå™¨")
    print("=" * 60)

    # åˆ›å»ºæ¨¡æ‹Ÿå™¨å®ä¾‹
    simulator = MultiGPUSimulator()

    # è¿è¡Œå®éªŒï¼ˆå¯ä»¥é€‰æ‹©ç‰¹å®šçš„æ•°æ®é›†å’ŒGPUé…ç½®ï¼‰
    datasets = ["burstgpt_sample"]  # ä½¿ç”¨é‡‡æ ·æ•°æ®é›†å¿«é€Ÿæµ‹è¯•
    gpus = ["single_gpu", "dual_gpu", "quad_gpu"]  # æµ‹è¯•1-4å¡é…ç½®

    # è¿è¡Œç»¼åˆå®éªŒ
    results = simulator.run_comprehensive_experiment(datasets=datasets, gpus=gpus)

    # ç”ŸæˆæŠ¥å‘Šå’Œå›¾è¡¨
    if results:
        report_path = simulator.generate_summary_report()
        chart_path = simulator.create_performance_charts()
        json_path = simulator.save_results_json()

        print(f"\nğŸ‰ å®éªŒå®Œæˆï¼")
        print(f"ğŸ“„ æŠ¥å‘Š: {report_path}")
        print(f"ğŸ“Š å›¾è¡¨: {chart_path}")
        print(f"ğŸ’¾ æ•°æ®: {json_path}")
    else:
        print("âŒ å®éªŒå¤±è´¥ï¼Œæ²¡æœ‰ç”Ÿæˆç»“æœ")

if __name__ == "__main__":
    main()