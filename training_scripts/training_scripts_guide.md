# è®­ç»ƒè„šæœ¬ä½¿ç”¨æŒ‡å—

## ğŸ“ è®­ç»ƒè„šæœ¬ä½ç½®

### ç”Ÿäº§è®­ç»ƒè„šæœ¬ï¼ˆç®€åŒ–ç‰ˆï¼‰

| è„šæœ¬æ–‡ä»¶ | ç”¨é€” | ç‰¹ç‚¹ |
|---------|------|------|
| `simple_training.py` | **ç®€åŒ–è®­ç»ƒè„šæœ¬** | ä»…LSTMå’ŒDLinearï¼Œæ¨èä½¿ç”¨ |
| `production_training.py` | **ç”Ÿäº§ç¯å¢ƒè®­ç»ƒè„šæœ¬** | æ”¯æŒCPUå’ŒGPUè‡ªåŠ¨æ£€æµ‹ |
| `cpu_training.py` | **CPUä¸“ç”¨è®­ç»ƒè„šæœ¬** | CPUç¯å¢ƒä¼˜åŒ– |

### æµ‹è¯•å’ŒéªŒè¯è„šæœ¬

| è„šæœ¬æ–‡ä»¶ | ç”¨é€” |
|---------|------|
| `test_request_predictor.py` | åŸºç¡€è®­ç»ƒæµ‹è¯• |
| `show_existing_plots.py` | ç»“æœå¯è§†åŒ– |

## ğŸš€ å¿«é€Ÿå¼€å§‹

### æ–¹æ¡ˆ1ï¼šç®€åŒ–è®­ç»ƒï¼ˆæ¨èï¼‰
```bash
# æœ€ç®€å•çš„è®­ç»ƒæ–¹å¼
python simple_training.py

# æŒ‡å®šæ•°æ®è·¯å¾„å’Œé‡‡æ ·å¤§å°
python simple_training.py --data-path dataset/BurstGPT_1_cleaned.csv --sample-size 100000
```

### æ–¹æ¡ˆ2ï¼šç”Ÿäº§ç¯å¢ƒè®­ç»ƒ
```bash
# è‡ªåŠ¨æ£€æµ‹CPU/GPU
python production_training.py

# æŒ‡å®šæ•°æ®è·¯å¾„å’Œé‡‡æ ·å¤§å°
python production_training.py --data-path dataset/BurstGPT_1_cleaned.csv --sample-size 100000
```

### æ–¹æ¡ˆ3ï¼šCPUä¸“ç”¨è®­ç»ƒ
```bash
# CPUç¯å¢ƒå¿«é€Ÿè®­ç»ƒ
python cpu_training.py

# CPUç¯å¢ƒå°æ•°æ®é›†è®­ç»ƒ
python cpu_training.py --sample-size 50000
```

## ğŸ“‹ è¯¦ç»†ä½¿ç”¨æ–¹æ³•

### 1. ç®€åŒ–è®­ç»ƒè„šæœ¬è¯¦è§£ï¼ˆæ¨èï¼‰

**simple_training.py** - ä¸»è¦ç‰¹ç‚¹ï¼š
- ä»…æ”¯æŒLSTMå’ŒDLinearæ¨¡å‹
- è‡ªåŠ¨è®¾å¤‡æ£€æµ‹å’Œä¼˜åŒ–
- æœ€ç®€åŒ–çš„APIå’Œé…ç½®
- åŒ…å«é¢„æµ‹æµ‹è¯•åŠŸèƒ½

```bash
# åŸºæœ¬ç”¨æ³•
python simple_training.py

# æŒ‡å®šæ•°æ®è·¯å¾„å’Œé‡‡æ ·å¤§å°
python simple_training.py \
  --data-path dataset/BurstGPT_1_cleaned.csv \
  --sample-size 100000
```

**å‚æ•°è¯´æ˜ï¼š**
- `--data-path`: æ•°æ®æ–‡ä»¶è·¯å¾„
- `--sample-size`: æ•°æ®é‡‡æ ·å¤§å°

### 2. ç”Ÿäº§ç¯å¢ƒè®­ç»ƒè„šæœ¬è¯¦è§£

**production_training.py** - ä¸»è¦ç‰¹ç‚¹ï¼š
- è‡ªåŠ¨æ£€æµ‹CPU/GPUè®¾å¤‡
- å®Œæ•´çš„ç”Ÿäº§çº§é…ç½®
- æ”¯æŒæ¨¡å‹ä¿å­˜åŠŸèƒ½

```bash
# åŸºæœ¬ç”¨æ³•
python production_training.py

# é«˜çº§ç”¨æ³•
python production_training.py \
  --data-path dataset/BurstGPT_1_cleaned.csv \
  --sample-size 100000 \
  --model-dir models
```

**å‚æ•°è¯´æ˜ï¼š**
- `--data-path`: æ•°æ®æ–‡ä»¶è·¯å¾„
- `--sample-size`: æ•°æ®é‡‡æ ·å¤§å°
- `--model-dir`: æ¨¡å‹ä¿å­˜ç›®å½•

### 3. CPUä¸“ç”¨è®­ç»ƒè„šæœ¬è¯¦è§£

**cpu_training.py** - CPUä¼˜åŒ–ç‰¹ç‚¹ï¼š
- å‡å°‘åºåˆ—é•¿åº¦ (80 vs 100)
- å‡å°‘è®­ç»ƒè½®æ•° (50 vs 100)
- å‡å°‘æ‰¹é‡å¤§å° (32 vs 64)
- æ›´å°çš„æ•°æ®é›†é»˜è®¤å€¼

```bash
# CPUå¿«é€Ÿè®­ç»ƒ
python cpu_training.py

# CPUå°æ•°æ®é›†è®­ç»ƒ
python cpu_training.py --sample-size 30000
```

### 4. è‡ªå®šä¹‰è®­ç»ƒè„šæœ¬

åˆ›å»ºä½ çš„è®­ç»ƒè„šæœ¬ `custom_training.py`ï¼š

```python
#!/usr/bin/env python3
"""
è‡ªå®šä¹‰è®­ç»ƒè„šæœ¬ç¤ºä¾‹
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from simple_training import SimpleTrainer

def main():
    # åˆ›å»ºç®€åŒ–è®­ç»ƒå™¨
    trainer = SimpleTrainer()

    # è¿è¡Œè‡ªå®šä¹‰è®­ç»ƒ
    success = trainer.run_simple_training(
        data_path='dataset/BurstGPT_1_cleaned.csv',
        sample_size=50000  # ä½¿ç”¨5ä¸‡æ¡æ•°æ®
    )

    if success:
        print("è‡ªå®šä¹‰è®­ç»ƒå®Œæˆ!")
    else:
        print("è®­ç»ƒå¤±è´¥!")

if __name__ == "__main__":
    main()
```

## ğŸ”§ ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²

### 1. è®­ç»ƒé…ç½®å»ºè®®

**GPUç¯å¢ƒé…ç½®ï¼š**
```bash
# å¤§è§„æ¨¡GPUè®­ç»ƒ
python production_training.py \
  --sample-size 200000 \
  --models lstm dlinear
```

**CPUç¯å¢ƒé…ç½®ï¼š**
```bash
# å¿«é€ŸCPUè®­ç»ƒ
python cpu_training.py \
  --sample-size 50000 \
  --models lstm
```

### 2. æ¨¡å‹ç®¡ç†

è®­ç»ƒå®Œæˆåï¼Œæ¨¡å‹å°†ä¿å­˜åœ¨ `models/` ç›®å½•ï¼š

```
models/
â”œâ”€â”€ production_lstm_20250926_143000.pth
â”œâ”€â”€ production_dlinear_20250926_143000.pth
â””â”€â”€ cpu_lstm_20250926_143000.pth
```

### 3. ç”Ÿäº§ç¯å¢ƒä½¿ç”¨

è®­ç»ƒå¥½çš„é¢„æµ‹å™¨å¯ä»¥ç›´æ¥ç”¨äºé¢„æµ‹ï¼š

```python
from predictor.request_predictor import RequestPredictor
import pandas as pd

# åˆ›å»ºé¢„æµ‹å™¨ï¼ˆè‡ªåŠ¨ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹ï¼‰
predictor = RequestPredictor()

# è¿›è¡Œé¢„æµ‹
historical_data = pd.read_csv('dataset/BurstGPT_1_cleaned.csv', nrows=1000)
prediction = predictor.predict_next_request(historical_data)

# æŸ¥çœ‹é¢„æµ‹ç»“æœ
print("é¢„æµ‹ç»“æœ:")
for model_name, pred in prediction['predictions'].items():
    if 'error' not in pred:
        print(f"{model_name}:")
        print(f"  æ—¶é—´æˆ³: {pred['timestamp']}")
        print(f"  è¯·æ±‚tokens: {pred['request_tokens']}")
        print(f"  å“åº”tokens: {pred['response_tokens']}")
        if 'confidence' in pred:
            print(f"  ç½®ä¿¡åº¦: {pred['confidence']}")
```

## ğŸ“Š è®­ç»ƒç»“æœ

### è®­ç»ƒè¾“å‡ºç¤ºä¾‹
```
ğŸš€ ç®€åŒ–é¢„æµ‹æ¨¡å‹è®­ç»ƒ
========================================

åŠ è½½æ•°æ®
------------------------------
æ•°æ®æ–‡ä»¶: dataset/BurstGPT_1_cleaned.csv
åŸå§‹æ•°æ®: 1,404,294 æ¡è®°å½•
é‡‡æ ·åˆ°: 100,000 æ¡è®°å½•
æ¸…ç†åæ•°æ®: 99,987 æ¡è®°å½•

æ¨¡å‹è®­ç»ƒ
------------------------------
å¼€å§‹è®­ç»ƒ LSTM + DLinear æ¨¡å‹...
è®­ç»ƒæ•°æ®: 99,987 æ¡è®°å½•

è®­ç»ƒç»“æœ:
[OK] lstm:
    æœ€ç»ˆæŸå¤±: 0.0234
    è®­ç»ƒè½®æ•°: 78
[OK] dlinear:
    æœ€ç»ˆæŸå¤±: 0.0189
    è®­ç»ƒè½®æ•°: 95

æˆåŠŸè®­ç»ƒ: 2/2 ä¸ªæ¨¡å‹

æµ‹è¯•é¢„æµ‹
------------------------------
é¢„æµ‹ç»“æœ:
  lstm:
    æ—¶é—´æˆ³: 1234567.89
    è¯·æ±‚tokens: 150
    å“åº”tokens: 300
    ç½®ä¿¡åº¦: 0.856
  dlinear:
    æ—¶é—´æˆ³: 1234567.92
    è¯·æ±‚tokens: 145
    å“åº”tokens: 295
    ç½®ä¿¡åº¦: 0.912

è®­ç»ƒæ‘˜è¦
------------------------------
è®­ç»ƒæ—¶é—´: 2025-09-26 14:30:00
æ•°æ®è§„æ¨¡: 99,987 æ¡è®°å½•
æˆåŠŸè®­ç»ƒ: 2/2 ä¸ªæ¨¡å‹
æˆåŠŸç‡: 100.0%
lstm: æŸå¤± = 0.0234
dlinear: æŸå¤± = 0.0189

ä½¿ç”¨æ–¹æ³•:
1. ç›´æ¥ä½¿ç”¨è®­ç»ƒå¥½çš„é¢„æµ‹å™¨:
   predictor = RequestPredictor()
   prediction = predictor.predict_next_request(historical_data)
2. é¢„æµ‹ç»“æœåŒ…å«LSTMå’ŒDLinearçš„ç‹¬ç«‹é¢„æµ‹
```

## ğŸ” æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **CUDAå†…å­˜ä¸è¶³**
```bash
# å‡å°‘æ•°æ®é‡‡æ ·å¤§å°
python simple_training.py --sample-size 50000

# æˆ–ä½¿ç”¨CPUè®­ç»ƒ
python cpu_training.py --sample-size 30000
```

2. **æ•°æ®æ–‡ä»¶æœªæ‰¾åˆ°**
```bash
# ç¡®ä¿æ•°æ®æ–‡ä»¶å­˜åœ¨
ls dataset/BurstGPT_1_cleaned.csv

# æˆ–æŒ‡å®šæ­£ç¡®è·¯å¾„
python simple_training.py --data-path /path/to/your/data.csv
```

3. **æ¨¡å‹è®­ç»ƒå¤±è´¥**
```bash
# ä½¿ç”¨CPUè®­ç»ƒè¿›è¡Œè°ƒè¯•
python cpu_training.py --sample-size 10000
```

### æ€§èƒ½ä¼˜åŒ–å»ºè®®

1. **GPUç¯å¢ƒï¼š**
   - ä½¿ç”¨æ›´å¤§çš„æ•°æ®é›† (100000+)
   - è‡ªåŠ¨ä¼˜åŒ–æ‰¹é‡å¤§å°å’Œè®­ç»ƒè½®æ•°

2. **CPUç¯å¢ƒï¼š**
   - å‡å°‘æ•°æ®é‡‡æ ·å¤§å° (30000-50000)
   - ä½¿ç”¨cpu_training.pyä¼˜åŒ–å‚æ•°

## ğŸ“ æœ€ä½³å®è·µ

1. **æ¨èä½¿ç”¨ç®€åŒ–è„šæœ¬ï¼š**
   - `python simple_training.py` - æœ€ç®€å•çš„æ–¹å¼
   - è‡ªåŠ¨å¤„ç†æ‰€æœ‰é…ç½®å’Œä¼˜åŒ–

2. **æ•°æ®å‡†å¤‡ï¼š**
   - ç¡®ä¿æ•°æ®æ–‡ä»¶å­˜åœ¨ä¸”æ ¼å¼æ­£ç¡®
   - æ£€æŸ¥å¿…éœ€åˆ—ï¼šTimestamp, Request tokens, Response tokens
   - æ¸…ç†å¼‚å¸¸å€¼å’Œç¼ºå¤±æ•°æ®

3. **æ¨¡å‹å¯¹æ¯”ï¼š**
   - LSTMï¼šé€‚åˆå¤æ‚çš„æ—¶é—´åºåˆ—æ¨¡å¼
   - DLinearï¼šé€‚åˆçº¿æ€§è¶‹åŠ¿å’Œå­£èŠ‚æ€§æ¨¡å¼
   - ä¸¤ä¸ªæ¨¡å‹ç‹¬ç«‹é¢„æµ‹ï¼Œå¯ä»¥é€‰æ‹©æ›´å‡†ç¡®çš„

4. **è®­ç»ƒç›‘æ§ï¼š**
   - è§‚å¯Ÿè®­ç»ƒæŸå¤±å€¼
   - ç›‘æ§è®­ç»ƒæˆåŠŸç‡
   - æ£€æŸ¥é¢„æµ‹æµ‹è¯•ç»“æœ

5. **ç”Ÿäº§éƒ¨ç½²ï¼š**
   - ä½¿ç”¨RequestPredictorç›´æ¥è¿›è¡Œé¢„æµ‹
   - æ¨¡å‹è‡ªåŠ¨åŒ…å«åœ¨é¢„æµ‹å™¨ä¸­
   - æ— éœ€æ‰‹åŠ¨åŠ è½½æ¨¡å‹æ–‡ä»¶

---

**æ€»ç»“ï¼š**
- **æ¨èä½¿ç”¨** `simple_training.py` - æœ€ç®€åŒ–çš„è®­ç»ƒæ–¹å¼
- **ç”Ÿäº§ç¯å¢ƒ** ä½¿ç”¨ `production_training.py` - æ”¯æŒæ¨¡å‹ä¿å­˜
- **CPUç¯å¢ƒ** ä½¿ç”¨ `cpu_training.py` - CPUä¼˜åŒ–å‚æ•°
- **æ‰€æœ‰è„šæœ¬** ä¸“æ³¨äºLSTMå’ŒDLinearæ¨¡å‹ï¼Œç§»é™¤äº†é«˜çº§æ¨¡å‹å¤æ‚æ€§