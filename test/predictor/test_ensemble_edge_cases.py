#!/usr/bin/env python3
"""
é›†æˆé¢„æµ‹å™¨è¾¹ç¼˜æƒ…å†µå’Œé”™è¯¯å¤„ç†æµ‹è¯•

æµ‹è¯•EnsemblePredictoråœ¨å„ç§å¼‚å¸¸æƒ…å†µä¸‹çš„ç¨³å®šæ€§å’Œé”™è¯¯å¤„ç†èƒ½åŠ›ã€‚
"""

import pandas as pd
import numpy as np
import logging
import sys
import os
import traceback
from pathlib import Path
from typing import List, Dict, Any

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(str(Path(__file__).parent.parent.parent))

from predictor.workload_predictor import WorkloadPredictor, ModelType, PredictionHorizon, PredictionResult
from predictor.ensemble_predictor import EnsemblePredictor, WeightStrategy
from predictor.simple_visualization import SimplePredictionVisualizer

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def create_basic_test_data(size: int = 100) -> pd.DataFrame:
    """åˆ›å»ºåŸºç¡€æµ‹è¯•æ•°æ®"""
    base_time = pd.Timestamp('2023-01-01')
    timestamps = [base_time + pd.Timedelta(milliseconds=i*100) for i in range(size)]

    # ç”Ÿæˆç®€å•çš„æµ‹è¯•æ•°æ®
    input_toks = np.random.poisson(100, size).astype(int)
    output_toks = (input_toks * np.random.uniform(2, 4, size)).astype(int)

    return pd.DataFrame({
        'arrival_time_ns': timestamps,
        'input_toks': input_toks,
        'output_toks': output_toks,
        'model_type': ['ChatGPT'] * size
    })


def test_ensemble_empty_models():
    """æµ‹è¯•ç©ºæ¨¡å‹åˆ—è¡¨çš„å¤„ç†"""
    logger.info("=== æµ‹è¯•ç©ºæ¨¡å‹åˆ—è¡¨å¤„ç† ===")

    try:
        # æµ‹è¯•ç©ºæ¨¡å‹åˆ—è¡¨
        ensemble_predictor = EnsemblePredictor(
            models=[],
            weight_strategy=WeightStrategy.STATIC,
            prediction_horizon=PredictionHorizon.SHORT_TERM,
            sequence_length=30
        )

        # åº”è¯¥èƒ½å¤Ÿå¤„ç†ç©ºæ¨¡å‹æƒ…å†µ
        test_data = create_basic_test_data(50)

        # è®­ç»ƒåº”è¯¥å¤±è´¥ä½†ä¸ä¼šå´©æºƒ
        try:
            training_results = ensemble_predictor.train(test_data)
            logger.info("ç©ºæ¨¡å‹è®­ç»ƒç»“æœ: æœ‰åˆç†çš„é”™è¯¯å¤„ç†")
        except Exception as e:
            logger.info(f"ç©ºæ¨¡å‹è®­ç»ƒå¤±è´¥ï¼ˆé¢„æœŸï¼‰: {e}")

        # é¢„æµ‹åº”è¯¥è¿”å›åˆæˆé¢„æµ‹
        historical_data = test_data.iloc[:-10]
        prediction_result = ensemble_predictor.predict(historical_data, steps=5)

        logger.info(f"ç©ºæ¨¡å‹é¢„æµ‹ç»“æœ:")
        logger.info(f"  è¯·æ±‚æ•°é‡: {len(prediction_result.predicted_requests)}")
        logger.info(f"  ç½®ä¿¡åº¦: {prediction_result.confidence:.3f}")
        logger.info(f"  æ¨¡å‹ç±»å‹: {prediction_result.prediction_metadata.get('model_type', 'N/A')}")

        # éªŒè¯åˆæˆé¢„æµ‹çš„æœ‰æ•ˆæ€§
        assert len(prediction_result.predicted_requests) > 0, "åº”è¯¥ç”Ÿæˆåˆæˆé¢„æµ‹"
        assert prediction_result.confidence > 0, "åº”è¯¥æœ‰åˆç†çš„ç½®ä¿¡åº¦"

        logger.info("âœ… ç©ºæ¨¡å‹åˆ—è¡¨å¤„ç†æµ‹è¯•é€šè¿‡")
        return True

    except Exception as e:
        logger.error(f"âŒ ç©ºæ¨¡å‹åˆ—è¡¨å¤„ç†æµ‹è¯•å¤±è´¥: {e}")
        traceback.print_exc()
        return False


def test_ensemble_insufficient_data():
    """æµ‹è¯•æ•°æ®ä¸è¶³æƒ…å†µ"""
    logger.info("=== æµ‹è¯•æ•°æ®ä¸è¶³æƒ…å†µ ===")

    try:
        # åˆ›å»ºæ•°æ®ä¸è¶³çš„æƒ…å†µ
        test_data = create_basic_test_data(20)  # éå¸¸å°‘çš„æ•°æ®

        ensemble_predictor = EnsemblePredictor(
            models=[ModelType.LSTM, ModelType.DLINEAR],
            weight_strategy=WeightStrategy.STATIC,
            prediction_horizon=PredictionHorizon.SHORT_TERM,
            sequence_length=30  # åºåˆ—é•¿åº¦å¤§äºæ•°æ®é‡
        )

        # è®­ç»ƒåº”è¯¥å¤„ç†æ•°æ®ä¸è¶³
        try:
            training_results = ensemble_predictor.train(test_data, validation_split=0.2)
            logger.info("æ•°æ®ä¸è¶³è®­ç»ƒå¤„ç†æˆåŠŸ")
        except Exception as e:
            logger.info(f"æ•°æ®ä¸è¶³è®­ç»ƒå¤±è´¥ï¼ˆé¢„æœŸï¼‰: {e}")

        # é¢„æµ‹åº”è¯¥èƒ½å¤Ÿå¤„ç†
        historical_data = test_data.iloc[:-5]
        prediction_result = ensemble_predictor.predict(historical_data, steps=10)

        logger.info(f"æ•°æ®ä¸è¶³é¢„æµ‹ç»“æœ:")
        logger.info(f"  è¯·æ±‚æ•°é‡: {len(prediction_result.predicted_requests)}")
        logger.info(f"  ç½®ä¿¡åº¦: {prediction_result.confidence:.3f}")

        # éªŒè¯ç»“æœçš„æœ‰æ•ˆæ€§
        assert prediction_result is not None, "åº”è¯¥è¿”å›é¢„æµ‹ç»“æœ"
        assert prediction_result.predicted_requests is not None, "åº”è¯¥æœ‰é¢„æµ‹è¯·æ±‚æ•°ç»„"

        logger.info("âœ… æ•°æ®ä¸è¶³æƒ…å†µæµ‹è¯•é€šè¿‡")
        return True

    except Exception as e:
        logger.error(f"âŒ æ•°æ®ä¸è¶³æƒ…å†µæµ‹è¯•å¤±è´¥: {e}")
        traceback.print_exc()
        return False


def test_ensemble_malformed_data():
    """æµ‹è¯•å¼‚å¸¸æ•°æ®å¤„ç†"""
    logger.info("=== æµ‹è¯•å¼‚å¸¸æ•°æ®å¤„ç† ===")

    try:
        # åˆ›å»ºå¼‚å¸¸æ•°æ®
        test_data = create_basic_test_data(100)

        # æ·»åŠ å¼‚å¸¸å€¼
        test_data.loc[10, 'input_toks'] = -100  # è´Ÿå€¼
        test_data.loc[20, 'output_toks'] = 0   # é›¶å€¼
        test_data.loc[30, 'input_toks'] = 100000  # æå¤§å€¼
        test_data.loc[40, 'arrival_time_ns'] = None  # ç¼ºå¤±æ—¶é—´æˆ³

        ensemble_predictor = EnsemblePredictor(
            models=[ModelType.LSTM],
            weight_strategy=WeightStrategy.STATIC,
            prediction_horizon=PredictionHorizon.SHORT_TERM,
            sequence_length=30
        )

        # è®­ç»ƒåº”è¯¥èƒ½å¤Ÿå¤„ç†å¼‚å¸¸æ•°æ®
        training_results = ensemble_predictor.train(test_data, validation_split=0.2)
        logger.info("å¼‚å¸¸æ•°æ®è®­ç»ƒå¤„ç†æˆåŠŸ")

        # é¢„æµ‹åº”è¯¥èƒ½å¤Ÿå¤„ç†
        historical_data = test_data.iloc[:-10]
        prediction_result = ensemble_predictor.predict(historical_data, steps=5)

        logger.info(f"å¼‚å¸¸æ•°æ®å¤„ç†ç»“æœ:")
        logger.info(f"  è¯·æ±‚æ•°é‡: {len(prediction_result.predicted_requests)}")
        logger.info(f"  ç½®ä¿¡åº¦: {prediction_result.confidence:.3f}")

        # éªŒè¯ç»“æœçš„æœ‰æ•ˆæ€§
        assert prediction_result is not None, "åº”è¯¥è¿”å›é¢„æµ‹ç»“æœ"
        assert len(prediction_result.predicted_requests) > 0, "åº”è¯¥æœ‰é¢„æµ‹è¯·æ±‚"

        logger.info("âœ… å¼‚å¸¸æ•°æ®å¤„ç†æµ‹è¯•é€šè¿‡")
        return True

    except Exception as e:
        logger.error(f"âŒ å¼‚å¸¸æ•°æ®å¤„ç†æµ‹è¯•å¤±è´¥: {e}")
        traceback.print_exc()
        return False


def test_ensemble_weight_extremes():
    """æµ‹è¯•æƒé‡æç«¯æƒ…å†µ"""
    logger.info("=== æµ‹è¯•æƒé‡æç«¯æƒ…å†µ ===")

    try:
        test_data = create_basic_test_data(150)

        # æµ‹è¯•æç«¯æƒé‡åˆ†é…
        extreme_weights = {
            ModelType.LSTM: 0.0,    # LSTMæƒé‡ä¸º0
            ModelType.DLINEAR: 1.0  # DLinearæƒé‡ä¸º1
        }

        ensemble_predictor = EnsemblePredictor(
            models=[ModelType.LSTM, ModelType.DLINEAR],
            weight_strategy=WeightStrategy.STATIC,
            prediction_horizon=PredictionHorizon.SHORT_TERM,
            sequence_length=30
        )

        # è®¾ç½®æç«¯æƒé‡
        ensemble_predictor.weights = extreme_weights

        # è®­ç»ƒ
        training_results = ensemble_predictor.train(test_data, validation_split=0.2)
        logger.info("æç«¯æƒé‡è®­ç»ƒæˆåŠŸ")

        # é¢„æµ‹
        historical_data = test_data.iloc[:-10]
        prediction_result = ensemble_predictor.predict(historical_data, strpseps=5)

        logger.info(f"æç«¯æƒé‡é¢„æµ‹ç»“æœ:")
        logger.info(f"  è¯·æ±‚æ•°é‡: {len(prediction_result.predicted_requests)}")
        logger.info(f"  ç½®ä¿¡åº¦: {prediction_result.confidence:.3f}")
        logger.info(f"  ä½¿ç”¨çš„æƒé‡: {ensemble_predictor.weights}")

        # éªŒè¯æƒé‡åˆ†é…
        assert ModelType.DLINEAR in ensemble_predictor.weights, "åº”è¯¥åŒ…å«DLinearæƒé‡"
        assert ensemble_predictor.weights[ModelType.DLINEAR] > 0, "DLinearæƒé‡åº”è¯¥å¤§äº0"

        logger.info("âœ… æƒé‡æç«¯æƒ…å†µæµ‹è¯•é€šè¿‡")
        return True

    except Exception as e:
        logger.error(f"âŒ æƒé‡æç«¯æƒ…å†µæµ‹è¯•å¤±è´¥: {e}")
        traceback.print_exc()
        return False


def test_ensemble_concurrent_predictions():
    """æµ‹è¯•å¹¶å‘é¢„æµ‹"""
    logger.info("=== æµ‹è¯•å¹¶å‘é¢„æµ‹ ===")

    try:
        import threading
        import time

        test_data = create_basic_test_data(200)

        ensemble_predictor = EnsemblePredictor(
            models=[ModelType.LSTM, ModelType.DLINEAR],
            weight_strategy=WeightStrategy.STATIC,
            prediction_horizon=PredictionHorizon.SHORT_TERM,
            sequence_length=30
        )

        # è®­ç»ƒ
        training_results = ensemble_predictor.train(test_data, validation_split=0.2)
        logger.info("å¹¶å‘é¢„æµ‹è®­ç»ƒæˆåŠŸ")

        # å¹¶å‘é¢„æµ‹æµ‹è¯•
        results = []
        errors = []

        def predict_worker(worker_id):
            try:
                historical_data = test_data.iloc[:-15]
                prediction_result = ensemble_predictor.predict(historical_data, steps=5)
                results.append({
                    'worker_id': worker_id,
                    'prediction_count': len(prediction_result.predicted_requests),
                    'confidence': prediction_result.confidence
                })
                logger.info(f"Worker {worker_id} é¢„æµ‹å®Œæˆ")
            except Exception as e:
                errors.append(f"Worker {worker_id}: {e}")

        # åˆ›å»ºå¤šä¸ªçº¿ç¨‹
        threads = []
        for i in range(3):
            thread = threading.Thread(target=predict_worker, args=(i,))
            threads.append(thread)
            thread.start()

        # ç­‰å¾…æ‰€æœ‰çº¿ç¨‹å®Œæˆ
        for thread in threads:
            thread.join()

        logger.info(f"å¹¶å‘é¢„æµ‹ç»“æœ:")
        for result in results:
            logger.info(f"  Worker {result['worker_id']}: {result['prediction_count']} requests, confidence={result['confidence']:.3f}")

        if errors:
            logger.warning(f"å¹¶å‘é¢„æµ‹é”™è¯¯: {errors}")

        # éªŒè¯å¹¶å‘ç»“æœ
        assert len(results) == 3, "åº”è¯¥æœ‰3ä¸ªé¢„æµ‹ç»“æœ"
        assert len(errors) == 0, "ä¸åº”è¯¥æœ‰é”™è¯¯"

        logger.info("âœ… å¹¶å‘é¢„æµ‹æµ‹è¯•é€šè¿‡")
        return True

    except Exception as e:
        logger.error(f"âŒ å¹¶å‘é¢„æµ‹æµ‹è¯•å¤±è´¥: {e}")
        traceback.print_exc()
        return False


def test_ensemble_model_failure():
    """æµ‹è¯•æ¨¡å‹å¤±è´¥æƒ…å†µ"""
    logger.info("=== æµ‹è¯•æ¨¡å‹å¤±è´¥æƒ…å†µ ===")

    try:
        test_data = create_basic_test_data(150)

        ensemble_predictor = EnsemblePredictor(
            models=[ModelType.LSTM, ModelType.DLINEAR],
            weight_strategy=WeightStrategy.STATIC,
            prediction_horizon=PredictionHorizon.SHORT_TERM,
            sequence_length=30
        )

        # è®­ç»ƒ
        training_results = ensemble_predictor.train(test_data, validation_split=0.2)
        logger.info("æ¨¡å‹å¤±è´¥æµ‹è¯•è®­ç»ƒæˆåŠŸ")

        # æ¨¡æ‹Ÿæ¨¡å‹å¤±è´¥ - ç ´åä¸€ä¸ªæ¨¡å‹çš„æƒé‡
        original_weights = ensemble_predictor.weights.copy()
        ensemble_predictor.weights[ModelType.LSTM] = 0.0  # è®©LSTMå¤±æ•ˆ

        # é¢„æµ‹åº”è¯¥ä»ç„¶èƒ½å¤Ÿå·¥ä½œ
        historical_data = test_data.iloc[:-10]
        prediction_result = ensemble_predictor.predict(historical_data, steps=5)

        logger.info(f"æ¨¡å‹å¤±è´¥é¢„æµ‹ç»“æœ:")
        logger.info(f"  è¯·æ±‚æ•°é‡: {len(prediction_result.predicted_requests)}")
        logger.info(f"  ç½®ä¿¡åº¦: {prediction_result.confidence:.3f}")
        logger.info(f"  åŸå§‹æƒé‡: {original_weights}")
        logger.info(f"  å½“å‰æƒé‡: {ensemble_predictor.weights}")

        # éªŒè¯é¢„æµ‹ä»ç„¶æœ‰æ•ˆ
        assert prediction_result is not None, "åº”è¯¥è¿”å›é¢„æµ‹ç»“æœ"
        assert len(prediction_result.predicted_requests) > 0, "åº”è¯¥æœ‰é¢„æµ‹è¯·æ±‚"

        logger.info("âœ… æ¨¡å‹å¤±è´¥æƒ…å†µæµ‹è¯•é€šè¿‡")
        return True

    except Exception as e:
        logger.error(f"âŒ æ¨¡å‹å¤±è´¥æƒ…å†µæµ‹è¯•å¤±è´¥: {e}")
        traceback.print_exc()
        return False


def test_ensemble_memory_usage():
    """æµ‹è¯•å†…å­˜ä½¿ç”¨æƒ…å†µ"""
    logger.info("=== æµ‹è¯•å†…å­˜ä½¿ç”¨æƒ…å†µ ===")

    try:
        import psutil
        import os

        # è·å–åˆå§‹å†…å­˜ä½¿ç”¨
        process = psutil.Process(os.getpid())
        initial_memory = process.memory_info().rss / 1024 / 1024  # MB

        # åˆ›å»ºè¾ƒå¤§çš„æµ‹è¯•æ•°æ®
        test_data = create_basic_test_data(1000)

        ensemble_predictor = EnsemblePredictor(
            models=[ModelType.LSTM, ModelType.DLINEAR],
            weight_strategy=WeightStrategy.STATIC,
            prediction_horizon=PredictionHorizon.SHORT_TERM,
            sequence_length=50
        )

        # è®­ç»ƒ
        training_results = ensemble_predictor.train(test_data, validation_split=0.2)

        # è·å–è®­ç»ƒåå†…å­˜ä½¿ç”¨
        training_memory = process.memory_info().rss / 1024 / 1024  # MB

        # é¢„æµ‹
        historical_data = test_data.iloc[:-50]
        prediction_result = ensemble_predictor.predict(historical_data, steps=20)

        # è·å–é¢„æµ‹åå†…å­˜ä½¿ç”¨
        prediction_memory = process.memory_info().rss / 1024 / 1024  # MB

        memory_increase = prediction_memory - initial_memory

        logger.info(f"å†…å­˜ä½¿ç”¨æƒ…å†µ:")
        logger.info(f"  åˆå§‹å†…å­˜: {initial_memory:.2f} MB")
        logger.info(f"  è®­ç»ƒåå†…å­˜: {training_memory:.2f} MB")
        logger.info(f"  é¢„æµ‹åå†…å­˜: {prediction_memory:.2f} MB")
        logger.info(f"  å†…å­˜å¢é•¿: {memory_increase:.2f} MB")

        # éªŒè¯å†…å­˜ä½¿ç”¨æ˜¯å¦åˆç†
        assert memory_increase < 500, f"å†…å­˜å¢é•¿è¿‡å¤š: {memory_increase} MB"

        logger.info("âœ… å†…å­˜ä½¿ç”¨æƒ…å†µæµ‹è¯•é€šè¿‡")
        return True

    except Exception as e:
        logger.error(f"âŒ å†…å­˜ä½¿ç”¨æƒ…å†µæµ‹è¯•å¤±è´¥: {e}")
        traceback.print_exc()
        return False


def cleanup_test_files():
    """æ¸…ç†æµ‹è¯•æ–‡ä»¶"""
    test_files = ["test_ensemble_edge_*.png"]
    for pattern in test_files:
        import glob
        for file in glob.glob(pattern):
            if os.path.exists(file):
                os.remove(file)
                logger.info(f"æ¸…ç†æµ‹è¯•æ–‡ä»¶: {file}")


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    logger.info("å¼€å§‹é›†æˆé¢„æµ‹å™¨è¾¹ç¼˜æƒ…å†µå’Œé”™è¯¯å¤„ç†æµ‹è¯•...")

    test_functions = [
        ("ç©ºæ¨¡å‹åˆ—è¡¨å¤„ç†", test_ensemble_empty_models),
        ("æ•°æ®ä¸è¶³æƒ…å†µ", test_ensemble_insufficient_data),
        ("å¼‚å¸¸æ•°æ®å¤„ç†", test_ensemble_malformed_data),
        ("æƒé‡æç«¯æƒ…å†µ", test_ensemble_weight_extremes),
        ("å¹¶å‘é¢„æµ‹", test_ensemble_concurrent_predictions),
        ("æ¨¡å‹å¤±è´¥æƒ…å†µ", test_ensemble_model_failure),
        ("å†…å­˜ä½¿ç”¨æƒ…å†µ", test_ensemble_memory_usage)
    ]

    passed_tests = 0
    total_tests = len(test_functions)

    try:
        for test_name, test_func in test_functions:
            logger.info(f"\n{'='*60}")
            logger.info(f"å¼€å§‹æµ‹è¯•: {test_name}")
            logger.info(f"{'='*60}")

            try:
                if test_func():
                    logger.info(f"âœ… {test_name} æµ‹è¯•é€šè¿‡")
                    passed_tests += 1
                else:
                    logger.error(f"âŒ {test_name} æµ‹è¯•å¤±è´¥")
            except Exception as e:
                logger.error(f"âŒ {test_name} æµ‹è¯•å´©æºƒ: {e}")
                traceback.print_exc()

        logger.info(f"\n{'='*60}")
        logger.info("æµ‹è¯•æ€»ç»“")
        logger.info(f"{'='*60}")
        logger.info(f"é€šè¿‡æµ‹è¯•: {passed_tests}/{total_tests}")
        logger.info(f"é€šè¿‡ç‡: {passed_tests/total_tests*100:.1f}%")

        if passed_tests == total_tests:
            logger.info("ğŸ‰ æ‰€æœ‰è¾¹ç¼˜æƒ…å†µæµ‹è¯•é€šè¿‡ï¼")
            return True
        else:
            logger.error("âŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥")
            return False

    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•è¿‡ç¨‹å‡ºé”™: {e}")
        traceback.print_exc()
        return False

    finally:
        cleanup_test_files()


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)